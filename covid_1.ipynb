{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02169fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "from tensorflow import keras\n",
    "from keras.optimizers import Adam\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.utils import plot_model\n",
    "#from keras.layers import Activation, Dropout, Convolution2D, GlobalAveragePooling2D\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "\n",
    "from keras.layers.core import Dense, Dropout, Flatten\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D, SeparableConv2D\n",
    "\n",
    "from keras.layers import Activation, Dropout, Convolution2D, GlobalAveragePooling2D\n",
    "from sklearn.model_selection import StratifiedKFold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "568f9298",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data =r\"C:\\Users\\91968\\Desktop\\Dive Into DL\\covid_1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f563bc7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['COVID', 'NORMAL']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52475397",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = []\n",
    "sizes=[]\n",
    "\n",
    "for directory in os.listdir(train_data):\n",
    "    path = os.path.join(train_data, directory)\n",
    "    if not os.path.isdir(path):\n",
    "        continue\n",
    "    for item in os.listdir(path):\n",
    "        img = cv2.imread(os.path.join(path, item))\n",
    "        #img = cv2.cvtColor(img,  cv2.COLOR_BGR2GRAY)\n",
    "        #img = cv2.resize(img, (224, 224))\n",
    "        train_df.append([img, directory])\n",
    "        sizes.append(img.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a0df0f70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total instances in train_df :  1836\n",
      "shape of x-ray image :  (299, 299, 3)\n"
     ]
    }
   ],
   "source": [
    "print('total instances in train_df : ',len(train_df))\n",
    "print('shape of x-ray image : ',train_df[0][0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a889b7dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1836, 299, 299, 3)\n",
      "(1836,)\n"
     ]
    }
   ],
   "source": [
    "y_train=[]\n",
    "X_train=[]\n",
    "\n",
    "for x,y in train_df:\n",
    "    X_train.append(x)\n",
    "    y_train.append(y)\n",
    "    \n",
    "\n",
    "for i in range(len(y_train)):\n",
    "    if y_train[i]=='NORMAL':\n",
    "        y_train[i]=0\n",
    "    else:\n",
    "        y_train[i]=1\n",
    "        \n",
    "        \n",
    "X_train=np.array(X_train)\n",
    "y_train=np.array(y_train)\n",
    "\n",
    "\n",
    "X_train=X_train/255\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "\n",
    "# X_train=X_train.reshape(len(X_train),224,224,1)\n",
    "# print('Shape : ' , X_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03ef6dcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6e5f96b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels.h5\n",
      "553467904/553467096 [==============================] - 52s 0us/step\n",
      "553476096/553467096 [==============================] - 52s 0us/step\n",
      "Model: \"vgg16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 224, 224, 3)]     0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "fc1 (Dense)                  (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "fc2 (Dense)                  (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "predictions (Dense)          (None, 1000)              4097000   \n",
      "=================================================================\n",
      "Total params: 138,357,544\n",
      "Trainable params: 138,357,544\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "model = VGG16()\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7768e5ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def AlexNet():\n",
    "    return tf.keras.models.Sequential([\n",
    "        # Here, we use a larger 11 x 11 window to capture objects. At the same\n",
    "        # time, we use a stride of 4 to greatly reduce the height and width of\n",
    "        # the output. Here, the number of output channels is much larger than\n",
    "        # that in LeNet\n",
    "        \n",
    "        tf.keras.layers.Conv2D(filters=64, kernel_size=76,input_shape=(299,299,3),\n",
    "                               activation='relu'),\n",
    "        \n",
    "        tf.keras.layers.Conv2D(filters=96, kernel_size=11, strides=4,\n",
    "                               activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2),\n",
    "        # Make the convolution window smaller, set padding to 2 for consistent\n",
    "        # height and width across the input and output, and increase the\n",
    "        # number of output channels\n",
    "        tf.keras.layers.Conv2D(filters=256, kernel_size=5, padding='same',\n",
    "                               activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2),\n",
    "        # Use three successive convolutional layers and a smaller convolution\n",
    "        # window. Except for the final convolutional layer, the number of\n",
    "        # output channels is further increased. Pooling layers are not used to\n",
    "        # reduce the height and width of input after the first two\n",
    "        # convolutional layers\n",
    "        tf.keras.layers.Conv2D(filters=384, kernel_size=3, padding='same',\n",
    "                               activation='relu'),\n",
    "        tf.keras.layers.Conv2D(filters=384, kernel_size=3, padding='same',\n",
    "                               activation='relu'),\n",
    "        tf.keras.layers.Conv2D(filters=256, kernel_size=3, padding='same',\n",
    "                               activation='relu'),\n",
    "        tf.keras.layers.MaxPool2D(pool_size=3, strides=2),\n",
    "        tf.keras.layers.Flatten(),\n",
    "        # Here, the number of outputs of the fully-connected layer is several\n",
    "        # times larger than that in LeNet. Use the dropout layer to mitigate\n",
    "        # overfitting\n",
    "        tf.keras.layers.Dense(4096, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        tf.keras.layers.Dense(4096, activation='relu'),\n",
    "        tf.keras.layers.Dropout(0.5),\n",
    "        # Output layer. Since we are using Fashion-MNIST, the number of\n",
    "        # classes is 10, instead of 1000 as in the paper\n",
    "        tf.keras.layers.Dense(1,activation='sigmoid')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "129c285f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 224, 224, 64)      1109056   \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 54, 54, 96)        743520    \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 26, 26, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 26, 26, 256)       614656    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 12, 12, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 12, 12, 384)       885120    \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 12, 12, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 12, 12, 256)       884992    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 5, 5, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 6400)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 4096)              26218496  \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 4097      \n",
      "=================================================================\n",
      "Total params: 48,568,737\n",
      "Trainable params: 48,568,737\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_2=AlexNet()\n",
    "model_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3e29a5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2.compile(optimizer=keras.optimizers.Adam(learning_rate=0.1),\n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "                  metrics=[keras.metrics.BinaryAccuracy(name='accuracy')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddaa3d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train : [ 144  145  146 ... 1833 1834 1835] validation : [  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  17\n",
      "  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  34  35\n",
      "  36  37  38  39  40  41  42  43  44  45  46  47  48  49  50  51  52  53\n",
      "  54  55  56  57  58  59  60  61  62  63  64  65  66  67  68  69  70  71\n",
      "  72  73  74  75  76  77  78  79  80  81  82  83  84  85  86  87  88  89\n",
      "  90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
      " 108 109 110 111 112 113 114 115 116 117 118 119 120 121 122 123 124 125\n",
      " 126 127 128 129 130 131 132 133 134 135 136 137 138 139 140 141 142 143\n",
      " 720 721 722 723 724 725 726 727 728 729 730 731 732 733 734 735 736 737\n",
      " 738 739 740 741 742 743 744 745 746 747 748 749 750 751 752 753 754 755\n",
      " 756 757 758 759 760 761 762 763 764 765 766 767 768 769 770 771 772 773\n",
      " 774 775 776 777 778 779 780 781 782 783 784 785 786 787 788 789 790 791\n",
      " 792 793 794 795 796 797 798 799 800 801 802 803 804 805 806 807 808 809\n",
      " 810 811 812 813 814 815 816 817 818 819 820 821 822 823 824 825 826 827\n",
      " 828 829 830 831 832 833 834 835 836 837 838 839 840 841 842 843 844 845\n",
      " 846 847 848 849 850 851 852 853 854 855 856 857 858 859 860 861 862 863\n",
      " 864 865 866 867 868 869 870 871 872 873 874 875 876 877 878 879 880 881\n",
      " 882 883 884 885 886 887 888 889 890 891 892 893 894 895 896 897 898 899\n",
      " 900 901 902 903 904 905 906 907 908 909 910 911 912 913 914 915 916 917\n",
      " 918 919 920 921 922 923 924 925 926 927 928 929 930 931 932 933 934 935\n",
      " 936 937 938 939 940 941 942 943]\n",
      "Epoch 1/10\n"
     ]
    }
   ],
   "source": [
    "\n",
    "accuracy=[]\n",
    "skf=StratifiedKFold(n_splits=5,random_state=None)\n",
    "skf.get_n_splits(X_train,y_train)\n",
    "for train_index,test_index in skf.split(X_train,y_train):\n",
    "    print('train :' ,train_index ,'validation :', test_index)\n",
    "    X1_train,X1_test=X_train[train_index],X_train[test_index]\n",
    "    y1_train,y1_test=y_train[train_index],y_train[test_index]\n",
    "    \n",
    "    \n",
    "    history=model_2.fit(X1_train,y1_train,\n",
    "                    epochs=10,\n",
    "                    batch_size=64,\n",
    "                    #validation_data=(X_test,y_test),\n",
    "                    #class_weight=class_weight,\n",
    "                    callbacks=[tf.keras.callbacks.EarlyStopping(monitor='accuracy',patience=1,mode='auto')]   \n",
    "                 )\n",
    "    \n",
    "    prediction=model_2.predict(X1_test)\n",
    "    score=accuracy_score(prediction,y1_test)\n",
    "    accuracy.append(score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdf494bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
